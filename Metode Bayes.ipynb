import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import time
import matplotlib.pyplot as plt
import random
from collections import Counter as ct

from sklearn.naive_bayes import GaussianNB
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score 

from google.colab import drive
drive.mount('/content/gdrive')

data2 = pd.read_csv('gdrive/My Drive/DataBCA_5tahun.csv')
print(data2)

data2['Date'] = pd.to_datetime(data2['Date'])
print(data2)

data2 = data2.set_index('Date')
sns.set(rc={'figure.figsize':(8, 2)}) adj_close = data2['Adj Close']
data2.loc['2014': '2019', 'Adj Close'].plot(linewidth=0.5);

fig = plt.figure(figsize=(20,12))
fig.suptitle ('BBCA Stock price comparison 2014 - 2019')
ax1 = fig.add_subplot(231)
ax1.set_title('2014')
ax1 = data2.loc['2014', 'Adj Close'].plot()
ax1.set_ylabel('BBCA stock price in rupiah');
ax2 = fig.add_subplot(232)
ax2.set_title('2015')
ax2 = data2.loc['2015', 'Adj Close'].plot()
ax2.set_ylabel('BBCA stock price in rupiah');
ax3 = fig.add_subplot(233)
ax3.set_title('2016')
ax3 = data2.loc['2016', 'Adj Close'].plot()
ax3.set_ylabel('BBCA stock price in rupiah');
ax4 = fig.add_subplot(234)
ax4.set_title('2017')
ax4 = data2.loc['2017', 'Adj Close'].plot()
ax4.set_ylabel('BBCA stock price in rupiah');
ax5 = fig.add_subplot(235)
ax5.set_title('2018')
ax5 = data2.loc['2018', 'Adj Close'].plot()
ax5.set_ylabel('BBCA stock price in rupiah');
ax6 = fig.add_subplot(236)
ax6.set_title('2019')
ax6 = data2.loc['2019', 'Adj Close'].plot()
ax6.set_ylabel('BBCA stock price in rupiah');

adj close = data2['Adj Close']
time = np.linspace(1, len(adj_close), len(adj_close))
plt.plot(time, adj_close, label = '2014-2019', ls = '--')
print(data2) 

base_data = "Volume"
data_p= 10000000
data2["Prediksi"] = np.where(
 data2[base_data] >= data_p,"Positive","Negative")
 print(data2["Prediksi"])

n_o_d = 4
variable_array= ["Open","High","Low","Close"]
variable_array.append("Prediksi")
data2 = data2[variable_array].dropna(axis=0,how='any')
print(data2)
train, test = train_test_split(data2, test_size=0.6, random_state=int(4))
gnb = GaussianNB()
newarr = []
newarr.extend(variable_array)
newarr.remove("Prediksi")
gnb.fit(train[newarr].values, train["Prediksi"])
result = gnb.predict(test[newarr])
print(result)

print("Number of mislabeled points out of a total {} points : {}, performance {:05.2f}%"
 .format(
 test.shape[0],
 (test["Prediksi"] != result).sum(),
 100*(1-(test["Prediksi"] != result).sum()/test.shape[0])
 ))
test_data = pd.concat([test[newarr], test["Prediksi"]], axis=1)
test_data["Prediksi"] = result
print (test_data)

counts = ct(result)
count_p = counts['Positive']
count_n = counts['Negative']
slices = [count_p,count_n]
cols = ['b','c']
plt.pie(slices, labels=['Positive','Negative'],colors = cols,shadow=True,startangle=90,autopct='%1.1f%%')
plt.title("Prediksi")
plt.legend()
plt.show()
